[[installing-cloudforms]]
== Installing {product-title}

{product-title} can be installed on OpenShift Container Platform in a few steps. 

This procedure uses a template to deploy a multi-pod {product-title_short} appliance with the database stored in a persistent volume on OpenShift Container Platform. It provides a step-by-step setup, including cluster administrative tasks as well as information and commands for the application developer using the deployment. 

The ultimate goal of the deployment is to be able to deconstruct the {product-title_short} appliance into several containers running on a pod or a series of pods. 

Running the {product-title_short} appliance in a series of pods has several advantages. For example, running each worker in a separate pod allows OpenShift Container Platform to manage worker processes and reduce worker memory consumption. OpenShift can also easily scale workers by adding or removing pods, and perform upgrades by using images.

There are two options for installing {product-title_short} on OpenShift:

* During OpenShift Container Platform 3.7 installation:
** When you install OpenShift Container Platform 3.7, you have the option to install {product-title_short} inside OpenShift at the time. This method leverages the Ansible installer to run and deploy the {product-title_short} template, instead of building the environment manually. See the  link:https://access.redhat.com/documentation/en-us/openshift_container_platform/3.7/html-single/release_notes/index#ocp-37-installation[OpenShift Container Platform 3.7 Release Notes] for details.
* Manual install on an existing OpenShift Container Platform environment:
** Deploy {product-title_short} pods using the {product-title_short} template (_.yaml_ file). This is the method described in this guide.

After deployment, you can configure the {product-title_short} environment to use any external authentication configurations supported by {product-title_short}.

[[prerequisites]]
=== Prerequisites

To successfully deploy a {product-title_short} appliance on OpenShift Container Platform, you need a functioning *OpenShift Container Platform 3.7* install with the following configured:

* NFS or other compatible volume provider
* A `cluster-admin` user
* A regular user (such as an application developer)

[IMPORTANT]
====
OpenShift Container Platform 3.7 is required for this installation. Red Hat has not tested this procedure with earlier versions of OpenShift Container Platform.
====

==== Cluster Sizing

To avoid deployment failures due to resource starvation, Red Hat recommends the following minimum cluster size for a test environment:

* 1 master node with at least 8 vCPUs and 12GB RAM
* 2 schedulable nodes with at least 4 vCPUs and 8GB RAM
* 25GB storage for {product-title_short} physical volume use

These recommendations assume {product-title_short} is the only application running on this cluster. Alternatively, you can provision an infrastructure node to run registry, metrics, router, and logging pods.

Each {product-title_short} application pod will consume at least 3GB RAM on initial deployment (without providers added). RAM consumption increases depending on the appliance use. For example, after adding providers, expect higher resource consumption.

==== Limitations

The following limitations exist when deploying this version of {product-title_short} on OpenShift Container Platform 3.7:

* This configuration cannot run on public OpenShift (OpenShift.io and OpenShift Dedicated environments) because of necessary privileges
* The Embedded Ansible pod must run as a privileged pod
* OpenShift cannot independently scale workers 
* A highly available database is not supported in PostgreSQL pods

[[templates-images]]
==== Templates and Images

ifdef::cfme[]
The {product-title_short} deployment uses `.yaml` template files to create the appliance, including `cfme-template.yaml`, which is the {product-title_short} template used for the deployment, and `cfme-pv-example.yaml` and `cfme-pv-app-example.yaml`, two pod volume files. 

These templates are available in RPMs from Red Hat-provided image streams. To obtain the templates:

. Configure image streams as described in link:https://access.redhat.com/documentation/en-us/openshift_container_platform/3.7/html/installation_and_configuration/install-config-imagestreams-templates#is-templates-prereqs[OpenShift Container Platform _Installation and Configuration_].
. After loading the image streams and templates, the templates will be available on your OpenShift system in `/usr/share/ansible/openshift-ansible/roles/openshift_examples/files/examples/v3.7/cfme-templates`.

The {product-title_short} template points to several image files to create the OpenShift pods that comprise the appliance. These image files are obtained from the https://access.redhat.com/containers/?product=Red%20Hat%20CloudForms%20#/search/cloudforms[Red Hat Container Catalog] during deployment.
endif::cfme[]

ifdef::miq[]
The {product-title_short} deployment uses `.yaml` template files to create the appliance, including `miq-template.yaml`, which is the {product-title_short} template used for the deployment, and `miq-pv-example.yaml` and `miq-pv-app-example.yaml`, two pod volume files. 

These templates are available in GitHub. You can obtain the templates by cloning the link:https://github.com/ManageIQ/manageiq-pods/tree/master/templates[GitHub repository], or with the following steps:

. Configure image streams as described in link:https://docs.openshift.com/container-platform/3.7/install_config/imagestreams_templates.html#is-templates-prereqs[OpenShift Container Platform _Installation and Configuration_].
. After loading the image streams and templates, the templates will be available on your OpenShift system in `/usr/share/ansible/openshift-ansible/roles/openshift_examples/files/examples/v3.7/cfme-templates`.
endif::miq[]


[[preparing-for-deployment]]
=== Preparing to Deploy {product-title_short}

To prepare for deploying the {product-title_short} appliance to OpenShift Container Platform, create a project, configure security contexts, and create persistent storage.

. As a regular user, log in to OpenShift: 
+
----
$ oc login -u <user> -p <password>
----
+
. Create a project with your desired parameters. The project name (`<your_project>` in this example) is mandatory, but `<description>` and `<display_name>` are optional: 
+
----
$ oc new-project <your_project> \
--description="<description>" \
--display-name="<display_name>"
----
+
. As the admin user, configure security context constraints (SCCs) for your OpenShift service accounts:
.. Add the `cfme-anyuid` service account to the `anyuid` SCC:
+
----
$ oc adm policy add-scc-to-user anyuid system:serviceaccount:<your-project>:cfme-anyuid
----
+
.. Add the `cfme-orchestrator` service account to the `anyuid` SCC:
+
----
$ oc adm policy add-scc-to-user anyuid system:serviceaccount:<your-project>:cfme-orchestrator
----
+
.. Add the `cfme-httpd` service account to the `anyuid` SCC:
+
----
$ oc adm policy add-scc-to-user anyuid system:serviceaccount:<your-project>:cfme-httpd
----
+ 
.. Add the `cfme-privileged` service account to the `privileged` SCC:
+
----
$ oc adm policy add-scc-to-user privileged system:serviceaccount:<your-project>:cfme-privileged
----
+
. Verify the SCCs are added correctly to the service accounts and project:
+
----
$ oc describe scc anyuid | grep Users
Users:					system:serviceaccount:<your-project>:cfme-anyuid,system:serviceaccount:<your-project>:cfme-httpd,system:serviceaccount:<your-project>:cfme-orchestrator
$ oc describe scc privileged | grep Users
Users:					system:admin,system:serviceaccount:openshift-infra:build-controller,system:serviceaccount:management-infra:management-admin,system:serviceaccount:management-infra:inspector-admin,system:serviceaccount:logging:aggregated-logging-fluentd,system:serviceaccount:<your-project>:cfme-privileged
----
+
[NOTE]
====
For more information on SCCs, see the https://docs.openshift.com/container-platform/3.7/admin_guide/manage_scc.html[OpenShift documentation].
====
+
. As the admin user, add the `httpd-configmap-generator` service account to the `httpd-scc-sysadmin` SCC before the Httpd Configmap Generator can run.
+
----
Users:        system:serviceaccount:<your-namespace>:httpd-configmap-generator
----
+
. Add the `view` and `edit` roles to the `cfme-orchestrator` service account:
+
----
$ oc policy add-role-to-user view system:serviceaccount:<your-project>:cfme-orchestrator -n <your-project>
$ oc policy add-role-to-user edit system:serviceaccount:<your-project>:cfme-orchestrator -n <your-project>
----
+
. As the admin user, prepare persistent storage for the deployment. (Skip this step if you have already configured persistent storage.) 
+
A basic {product-title_short} deployment needs at least two persistent volumes (PVs) to store {product-title_short} data. As the admin user, create two persistent volumes: one to host the {product-title_short} PostgreSQL database, and one to host the application data. 
+
Example NFS-backed volume templates are provided by `cfme-pv-db-example.yaml` and `cfme-pv-server-example.yaml`, available from the image stream or repository configured in xref:templates-images[]. 
+
[NOTE]
====
For NFS-backed volumes, ensure your NFS server firewall is configured to allow traffic on port 2049 (TCP) from the OpenShift cluster.

Red Hat recommends setting permissions for the pv-app (privileged pod volume) as 777, uid/gid 0 (owned by root). For more information on configuring persistent storage in OpenShift Container Platform, see the https://access.redhat.com/documentation/en-us/openshift_container_platform/3.7/html-single/installation_and_configuration/#configuring-persistent-storage[OpenShift Container Platform Installation and Configuration] guide.	
====
+
.. Configure your NFS server host details within these files, and edit any other settings needed to match your environment.
+
.. Create the two persistent volumes: 
+
------
$ oc create -f cfme-pv-db-example.yaml
$ oc create -f cfme-pv-server-example.yaml
------
+
.. Process the templates, editing the NFS_HOST parameter (mandatory) and any other parameters:
+ 
----
$ oc process cfme-pv-db-example.yaml -p NFS_HOST=nfs.example.com | oc create -f -
----
+
Alternatively, you can create the two persistent volumes and process the templates in a single command:
+
----
$ oc process cfme-pv-server-example.yaml -p NFS_HOST=nfs.example.com | oc create -f -
----
+
[NOTE]
====
There are three parameters required to process the template. Only NFS_HOST is required, PV_SIZE and BASE_PATH contain defaults that do not need editing unless desired:

* PV_SIZE - Defaults to the recommended PV size for the App/DB template (5Gi/15Gi respectively)
* BASE_PATH - Defaults to /exports
* NFS_HOST - No Default - Hostname or IP address of the NFS server
====
+
.. Verify the persistent volumes were created successfully: 
+
------
$ oc get pv
NAME                CAPACITY   ACCESSMODES   RECLAIMPOLICY   STATUS      CLAIM         STORAGECLASS   REASON    AGE
cfme-app            5Gi        RWO           Retain          Available                                          16s

cfme-db             15Gi       RWO           Retain          Available                                          49s
------
+
[NOTE]
====
Red Hat recommends validating NFS share connectivity from an OpenShift node before attempting a deployment.
====
+
. Increase the maximum number of imported images on ImageStream.
+
By default, OpenShift Container Platform can import five tags per image stream, but the {product-title_short} repositories contain more than five images for deployments.
+
You can modify this setting on the master node at `/etc/origin/master/master-config.yaml` so OpenShift can import additional images. 
+
.. Add the following at the end of the `/etc/origin/master/master-config.yaml` file: 
+
----
...
imagePolicyConfig:
  maxImagesBulkImportedPerRepository: 100
----
+
.. Restart the master service:
+
----
$ systemctl restart atomic-openshift-master
----
. On each OpenShift node, persistently enable the `container_manage_cgroup` SELinux boolean to allow container processes to make changes to the _cgroup_ configuration:
+
----
# setsebool -P container_manage_cgroup on
----





[[deploying-the-appliance]]
=== Deploying the {product-title_short} Appliance

To deploy the appliance on OpenShift Container Platform, create the {product-title_short} template and verify it is available in your project. 

. As a regular user, create the {product-title_short} template: 
+
------
$ oc create -f cfme-template.yaml
template "cloudforms" created
------
+
. Verify the template is available with your project: 
+
------
$ oc get templates
NAME         DESCRIPTION                                    PARAMETERS        OBJECTS
cloudforms   CloudForms appliance with persistent storage   18 (1 blank)      12
------
+
. (Optional) Customize the template’s deployment parameters. Use the following command to see the available parameters and descriptions:
+
------
$ oc process --parameters -n <your-project> cloudforms
------
+
To customize the deployment configuration parameters, run:
+
------
$ oc edit dc/<deployconfig_name>
------
+
. To deploy {product-title_short} from template using default settings, run: 
+
------
$ oc new-app --template=cloudforms
------
+
Alternatively, to deploy {product-title_short} from a template using customized settings, add the `-p` option and the desired parameters to the command. For example: 
+
------
$ oc new-app --template=cloudforms -p DATABASE_VOLUME_CAPACITY=2Gi,POSTGRESQL_MEM_LIMIT=4Gi,APPLICATION_DOMAIN=hostname
------
+
[IMPORTANT]
====
The `APPLICATION_DOMAIN` parameter specifies the hostname used to reach the {product-title_short} application, which eventually constructs the route to the {product-title_short} pod. If you do not specify the `APPLICATION_DOMAIN` parameter, the {product-title_short} application will not be accessible after the deployment; however, this can be fixed by changing the route. For more information on OpenShift template parameters, see the https://access.redhat.com/documentation/en-us/openshift_container_platform/3.7/html-single/developer_guide/#dev-guide-templates[OpenShift Container Platform Developer Guide].
====

[[deploying-the-appliance-external-db]]
==== Deploying the {product-title_short} Appliance Using an External Database

Before attempting to deploy {product-title_short} using an external database deployment, ensure the following conditions are satisfied:

* Your OpenShift cluster can access the external PostgreSQL server
* The {product-title_short} user, password, and role have been created on the external PostgreSQL server
* The intended {product-title_short} database is created, and ownership has been assigned to the {product-title_short} user

To deploy the appliance:

. Import the {product-title_short} external database template:
+
----
$ oc create -f templates/cfme-template-ext-db.yaml
----
+
. Launch the deployment with the following command. The database server IP address is required, and the other settings must match your remote PostgreSQL server.
+
----
$ oc new-app --template=cloudforms-ext-db -p DATABASE_IP=<server_ip> -p DATABASE_USER=<user> -p DATABASE_PASSWORD=<password> -p DATABASE_NAME=<database_name>
----

[[verifying-the-configuration]]
=== Verifying the Configuration

Verify the deployment was successful by running the following commands as a regular user under the {product-title_short} project:

[NOTE]
====
The first deployment can take several minutes to complete while OpenShift downloads the necessary images. 
====

. Confirm the {product-title_short} pod is bound to the correct security context constraints:
.. List and obtain the name of the `cfme-app` pod: 
+
------
$ oc get pod
NAME                 READY     STATUS    RESTARTS   AGE
cloudforms-0         1/1       Running   0          4m
httpd-1-w486v        1/1       Running   0          4m
memcached-1-4xtjc    1/1       Running   0          4m
postgresql-1-n5tm6   1/1       Running   0          4m
------
+
.. Export the configuration of the pod: 
+
------
$ oc export pod <cfme_pod_name>
------
+
.. Examine the output to verify that `openshift.io/scc` has the value `anyuid`: 
+
------
...
metadata:
  annotations:
    openshift.io/scc: anyuid
...
------
+
. Verify the persistent volumes are attached to the `postgresql` and `cfme-app` pods:
+
------
$ oc volume pods --all
pods/postgresql-1-437jg
  pvc/cfme-pgdb-claim (allocated 2GiB) as cfme-pgdb-volume
    mounted at /var/lib/pgsql/data
  secret/default-token-2se06 as default-token-2se06
    mounted at /var/run/secrets/kubernetes.io/serviceaccount
pods/cfme-1-s3bnp
  pvc/cfme (allocated 2GiB) as cfme-app-volume
    mounted at /persistent
  secret/default-token-9q4ge as default-token-9q4ge
    mounted at /var/run/secrets/kubernetes.io/serviceaccount
------
+
. Check the readiness of the {product-title_short} pod: 
+
[NOTE]
====
Allow approximately five minutes once pods are in running state for {product-title_short} to start responding on HTTPS.  
====
+
----
$ oc describe pods <cfme_pod_name>
...
Conditions:
  Type      Status
  Ready     True
Volumes:
...
----
+
. After you have successfully validated your {product-title_short} deployment, disable automatic image change triggers to prevent unintended upgrades.
+
By default, on initial deployments the automatic image change trigger is enabled. This could potentially start an unintended upgrade on a deployment if a newer image is found in the ImageStream.
+
Disable the automatic image change triggers for {product-title_short} deployment configurations (DCs) on each project with the following commands:
+
----
$ oc set triggers dc --manual -l app=cloudforms
deploymentconfig "memcached" updated
deploymentconfig "postgresql" updated

$ oc set triggers dc --from-config --auto -l app=cloudforms
deploymentconfig "memcached" updated
deploymentconfig "postgresql" updated
----
+
[NOTE]
====
The configuration change trigger is kept enabled; to have full control of your deployments, you can alternatively turn it off. See the https://access.redhat.com/documentation/en-us/openshift_container_platform/3.7/html-single/developer_guide/#dev-guide-triggering-builds[OpenShift Container Platform Developer Guide] for more information on deployment triggers.
====

=== Logging into {product-title_short}

As part of the deployment, a route to the {product-title_short} appliance is created for HTTPS access. 
Once the pods have been successfully deployed, you can log into {product-title_short}.

You can obtain the {product-title_short} host address from the project in the OpenShift user interface, or by opening a shell on the pod and getting the route information. 

. To open a shell on the pod, run:
+
----
$ oc rsh <pod_name> bash -l
----
+
. Get the route information:
+
----
$ oc get routes
NAME         HOST/PORT                   PATH                SERVICE      TERMINATION   LABELS
cloudforms   cfme.apps.e2e.example.com  cloudforms:443-tcp   passthrough                app=cloudforms
----
. Navigate to the reported URL/host on a web browser (in this example, `cfme.apps.e2e.example.com`).
.  Enter the default {product-title_short} credentials (Username: *admin* | Password: *smartvm*) for the initial login.
.  Click *Login*.




